{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Network in PyMC3\n",
    "(c) 2016 by Thomas Wiecki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.expanduser('~/work/git/github/taku-y/pymc3/'))\n",
    "\n",
    "%matplotlib inline\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, Y = datasets.make_blobs(n_samples=200, n_features=2, centers=2, cluster_std=3.0, \n",
    "#                           center_box=(-5.0, 5.0), shuffle=True, random_state=None)\n",
    "\n",
    "X, Y = make_moons(noise=0.2, random_state=0, n_samples=1000)\n",
    "X = scale(X)\n",
    "X = X.astype('float32')\n",
    "Y = Y.astype('float32')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[Y==0, 0], X[Y==0, 1])\n",
    "plt.scatter(X[Y==1, 0], X[Y==1, 1], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ordered(name, var, model=None):\n",
    "    order = T.constant(list(range(var.tag.test_value.shape[1])))\n",
    "    return pm.Potential(\n",
    "        name,\n",
    "        T.switch(T.eq(T.argsort(T.sum(var, axis=0)), order), 0, -np.inf),\n",
    "        model=model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn inputs and outputs into shared variables so that we can change them later\n",
    "import theano.tensor as tt\n",
    "\n",
    "# ann_input = tt.matrix()\n",
    "# ann_input.tag.test_value = X_train\n",
    "# ann_output = tt.vector()\n",
    "# ann_output.tag.test_value = Y_train\n",
    "\n",
    "ann_input = theano.shared(X_train)\n",
    "ann_output = theano.shared(Y_train)\n",
    "\n",
    "n_hidden = 5\n",
    "\n",
    "# Initialize random but sorted starting weights.\n",
    "init_1 = np.random.randn(X.shape[1], n_hidden)\n",
    "init_1 = init_1[:, np.argsort(init_1.sum(axis=0))]\n",
    "init_2 = np.random.randn(n_hidden, n_hidden)\n",
    "init_2 = init_2[:, np.argsort(init_2.sum(axis=0))]\n",
    "init_out = np.random.randn(n_hidden)\n",
    "init_out = init_out[np.argsort(init_out)]\n",
    "\n",
    "    \n",
    "with pm.Model() as neural_network:\n",
    "    # Weights from input to hidden layer\n",
    "    weights_in_1 = pm.Normal('w_in_1', 0, sd=1, shape=(X.shape[1], n_hidden), \n",
    "                             testval=init_1)\n",
    "    \n",
    "    # Weights from 1st to 2nd layer\n",
    "    weights_1_2 = pm.Normal('w_1_2', 0, sd=1, shape=(n_hidden, n_hidden), \n",
    "                             testval=init_2)\n",
    "    \n",
    "    # Weights from hidden layer to output\n",
    "    weights_2_out = pm.Normal('w_2_out', 0, sd=1, shape=(n_hidden,), \n",
    "                              testval=init_out)\n",
    "\n",
    "    # Build neural-network\n",
    "    a1 = T.dot(ann_input, weights_in_1)\n",
    "    act_1 = T.tanh(a1)\n",
    "    a2 = T.dot(act_1, weights_1_2)\n",
    "    act_2 = T.tanh(a2)\n",
    "    act_out = T.dot(act_2, weights_2_out)\n",
    "    \n",
    "    out = pm.Bernoulli('out', \n",
    "                       T.nnet.sigmoid(act_out),\n",
    "                       observed=ann_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation with ADVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_tensors = [ann_input, ann_output]\n",
    "minibatch_RVs = [out]\n",
    "\n",
    "def create_minibatch(data):\n",
    "    rng = np.random.RandomState(0)\n",
    "    \n",
    "    while True:\n",
    "        ixs = rng.randint(len(data), size=100)\n",
    "        yield data[ixs]\n",
    "\n",
    "minibatches = [\n",
    "    create_minibatch(X_train), \n",
    "    create_minibatch(Y_train),\n",
    "]\n",
    "\n",
    "total_size = len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with neural_network:\n",
    "    # Run advi_minibatch\n",
    "    advi_fit = pm.variational.advi_minibatch(\n",
    "        n=40000, minibatch_tensors=minibatch_tensors, \n",
    "        minibatch_RVs=minibatch_RVs, minibatches=minibatches, \n",
    "        total_size=total_size, learning_rate=1e-2, epsilon=1.0, \n",
    "        n_mcsamples=1\n",
    "    )\n",
    "plt.plot(advi_fit.elbo_vals)\n",
    "trace_advi = pm.variational.sample_vp(advi_fit, 500, neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace shared variables with testing set\n",
    "# (note that using this trick we could be streaming ADVI for big data)\n",
    "ann_input.set_value(X_test)\n",
    "ann_output.set_value(Y_test)\n",
    "\n",
    "# Creater posterior predictive samples\n",
    "ppc = pm.sample_ppc(trace_advi, model=neural_network, samples=500)\n",
    "pred = ppc['out'].mean(axis=0) > 0.5\n",
    "\n",
    "plt.scatter(X_test[Y_test==0, 0], X_test[Y_test==0, 1])\n",
    "plt.scatter(X_test[Y_test==1, 0], X_test[Y_test==1, 1], color='r')\n",
    "plt.title('Predicted labels in testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[pred==0, 0], X_test[pred==0, 1])\n",
    "plt.scatter(X_test[pred==1, 0], X_test[pred==1, 1], color='r')\n",
    "plt.title('Predicted labels in testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy = {}%'.format((Y_test == pred).mean() * 100))\n",
    "sns.regplot(ppc['out'].mean(axis=0), Y_test, logistic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at what the classifier has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.mgrid[-3:3:100j,-3:3:100j]\n",
    "grid_2d = grid.reshape(2, -1).T.astype('float32')\n",
    "dummy_out = np.ones(grid_2d.shape[0], dtype=np.int8)\n",
    "\n",
    "ann_input.set_value(grid_2d)\n",
    "ann_output.set_value(dummy_out)\n",
    "# Creater posterior predictive samples\n",
    "ppc = pm.sample_ppc(trace_advi, model=neural_network, samples=5000)\n",
    "pred_grid = ppc['out'].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(145, 280, s=85, l=25, as_cmap=True)\n",
    "# plt.contourf(*grid, pred_grid.reshape(100, 100), cmap=cmap)\n",
    "plt.contourf(grid[0], grid[1], pred_grid.reshape(100, 100), cmap=cmap)\n",
    "plt.scatter(X_test[pred==0, 0], X_test[pred==0, 1], alpha=0.5)\n",
    "plt.scatter(X_test[pred==1, 0], X_test[pred==1, 1], color='r', alpha=0.5)\n",
    "#plt.title('Predicted labels in testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
